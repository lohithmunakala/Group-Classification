{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group Classification Tensroflow GPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX5MYkyaH_Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import config\n",
        "import clr_callback\n",
        "import learningratefinder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhDsxL7TFfFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6d282396-296d-480e-f909-93c82ad16143"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clr_callback.py  \u001b[0m\u001b[01;34mdrive\u001b[0m/                 \u001b[01;34m__pycache__\u001b[0m/\n",
            "config.py        learningratefinder.py  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUYzBFt9uyva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aed4711b-31f9-44cc-fede-9d48b81bb998"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EIFpVC2E1i6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abb171b1-c8b9-44ce-fa72-e03e8f0a3c06"
      },
      "source": [
        "print(config.DATASET_PATH_COLAB)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Group_Classification/input\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4jMMZlS8VHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "f0a67928-d58c-46e0-b631-0d85c0c35286"
      },
      "source": [
        "#setting agg as bg as this will save the imgs in the bg\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "#importing the libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from learningratefinder import LearningRateFinder\n",
        "from clr_callback import CyclicLR\n",
        "import config\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-f\", \"--lr-find\", type=int , default= 0,\n",
        "#                 help=\"whether or not to find optimal learning rate\")\n",
        "\n",
        "# args = vars(ap.parse_args())\n",
        "args={}\n",
        "args[\"lr_find\"] = 0\n",
        "\n",
        "\n",
        "print(\"[INFO] LOADING IMAGES...\")\n",
        "imagePaths = list(paths.list_images(config.DATASET_PATH_COLAB))\n",
        "# print(imagePaths)\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "i = 0\n",
        "#looping over imagePaths\n",
        "for imagePath in imagePaths:\n",
        "    #extract the class label\n",
        "    # print(imagePath)\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    # print(label)\n",
        "    \n",
        "    #loading the image, converting it to RGB channel, and resize\n",
        "    #to be fixed at 224*224 \n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "\n",
        "    #update the data ans labels lists \n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        "    # print(data)\n",
        "    if i %100 ==0:\n",
        "        print(i)\n",
        "    i+= 1\n",
        "\n",
        "#converting the data and labels tp numpy array\n",
        "print(\"[INFO] PROCESSING DATA...\")\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "#perform one-hot encoding on the labels \n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "print(labels[0])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] LOADING IMAGES...\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "[INFO] PROCESSING DATA...\n",
            "[1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tnOT0kRU7yM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19a43ecc-e4ab-4a0a-a1e3-1f7ecf55a307"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3308, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l5xDj5d8X8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#partition the data into training and testing \n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "                                                 labels,\n",
        "                                                 test_size=config.TEST_SPLIT,\n",
        "                                                 random_state = 42)\n",
        "                                            \n",
        "\n",
        "#preparing the validation split from the training split\n",
        "(trainX, valX, trainY, valY) = train_test_split(trainX,\n",
        "                                                trainY,\n",
        "                                                test_size = config.VAL_SPLIT,\n",
        "                                                random_state = 84)\n",
        "\n",
        "#initialize the training data augmentation object \n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "            rotation_range= 30,\n",
        "            zoom_range = 0.15,\n",
        "            width_shift_range= 0.2,\n",
        "            height_shift_range= 0.2,\n",
        "            shear_range= 0.15,\n",
        "            horizontal_flip= True,\n",
        "            fill_mode=\"nearest\")\n",
        "    \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6dYwevfVTFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b628153c-eabc-4593-b9ca-3dff7e56cd9a"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2232, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4cv1ApwUyZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args[\"lr_find\"] = 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpgk3ZEM_DyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import ResNet152"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abdQiD9aVP5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82734e5a-365b-47fc-bacb-6e22035f4909"
      },
      "source": [
        "with tf.device(\"/gpu:0\"):\n",
        "    #loading the model \n",
        "    basemodel = ResNet50(weights= \"imagenet\",\n",
        "                    include_top= False,\n",
        "                    input_tensor = Input(shape=(224,224,3))\n",
        "                    )\n",
        "\n",
        "    #headmodel which will be placed on basemodel            \n",
        "    headmodel = basemodel.output\n",
        "    headmodel = Flatten(name=\"Flatten\")(headmodel)\n",
        "    headmodel = Dense(512, activation=\"relu\")(headmodel)\n",
        "    headmodel = Dropout(0.5)(headmodel)\n",
        "    headmodel = Dense(len(config.CLASSES), activation=\"softmax\")(headmodel)\n",
        "\n",
        "    #placing the headmodel on top of the base model\n",
        "    model = Model(inputs=basemodel.input, outputs=headmodel)\n",
        "\n",
        "    #freezing the layers of the basemodel\n",
        "    for layer in basemodel.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(\"[INFO] COMPILING MODEL ...\")\n",
        "\n",
        "    opt = SGD(lr = config.MIN_LR, momentum= 0.9)\n",
        "    model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = opt,\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "    #cheacking whether we have to perform finding optimal rate\n",
        "    if args[\"lr_find\"] > 0:\n",
        "        print(\"[INFO] finding learning rate...\")\n",
        "        lrf = LearningRateFinder(model)\n",
        "        lrf.find(\n",
        "            aug.flow(trainX, trainY, batch_size= config.BATHC_SIZE),\n",
        "            1e-10, 1e+1,\n",
        "            stepsPerEpoch= np.ceil((trainX.shape[0]/float(config.BATHC_SIZE))),\n",
        "            epochs= 20,\n",
        "            batchSize= config.BATHC_SIZE\n",
        "        )\n",
        "\n",
        "        #plotting the loss for various lrs\n",
        "        lrf.plot_loss()\n",
        "        plt.savefig(config.LRFIND_PLOT_PATH)\n",
        "\n",
        "        #exiting the script so as to change the lrs in the config file\n",
        "        print(\"[INFO] learning rate finder complete\")\n",
        "        print(\"[INFO] examine plots and adjust learning rates before training\")\n",
        "\n",
        "        #exit the script\n",
        "        sys.exit(0)\n",
        "\n",
        "    stepsize = config.STEP_SIZE *(trainX.shape[0] // config.BATHC_SIZE)\n",
        "    clr =  CyclicLR(\n",
        "        mode= config.CLR_METHOD,\n",
        "        base_lr=config.MIN_LR,\n",
        "        max_lr=config.MAX_LR,\n",
        "        step_size= stepsize\n",
        "    )\n",
        "\n",
        "\n",
        "    print([\"[INFO] training netwrok...\"])\n",
        "    H = model.fit(\n",
        "            aug.flow(trainX, trainY, batch_size= config.BATHC_SIZE),\n",
        "            validation_data = (valX, valY),\n",
        "            steps_per_epoch = trainX.shape[0] // config.BATHC_SIZE,\n",
        "            epochs = 25,\n",
        "            callbacks = [clr]\n",
        "            # verbose = 1\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"[INFO] EVALUATING THE NETWORK...\")\n",
        "\n",
        "    predictions = model.predict(testX, batch_size = config.BATHC_SIZE)\n",
        "\n",
        "    print(classification_report(testY.argmax(axis =1),\n",
        "        predictions.argmax(axis =1),\n",
        "        target_names = config.CLASSES))\n",
        "\n",
        "    print(\"[INFO] SERIALIZING NETWROK TO {} .... \".format(config.MODEL_PATH))\n",
        "    model.save(config.MODEL_PATH_COLAB)    \n",
        "\n",
        "\n",
        "    #plot that plots and saves the training history\n",
        "    N = np.arange(0, 25)\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, H.history[\"loss\"], label= \"train_loss\")\n",
        "    plt.plot(N, H.history[\"val_loss\"], label = \"val_loss\")\n",
        "    plt.plot(N, H.history[\"accuracy\"], label = \"train_acc\")\n",
        "    plt.plot(N, H.history[\"val_accuracy\"], label = \"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.ylabel(\"Loss / Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.legend(loc = \"lower left\")\n",
        "    plt.savefig(config.TRAINING_PLOT_PATH)\n",
        "\n",
        "\n",
        "    # plot the learning rate history\n",
        "    N = np.arange(0, len(clr.history[\"lr\"]))\n",
        "    plt.figure()\n",
        "    plt.plot(N, clr.history[\"lr\"])\n",
        "    plt.title(\"Cyclical Learning Rate (CLR)\")\n",
        "    plt.xlabel(\"Training Iterations\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.savefig(config.CLR_PLOT_PATH)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 3s 0us/step\n",
            "[INFO] COMPILING MODEL ...\n",
            "['[INFO] training netwrok...']\n",
            "Epoch 1/25\n",
            "69/69 [==============================] - 33s 480ms/step - loss: 2.4335 - accuracy: 0.3991 - val_loss: 1.0084 - val_accuracy: 0.5984\n",
            "Epoch 2/25\n",
            "69/69 [==============================] - 32s 463ms/step - loss: 1.3974 - accuracy: 0.5605 - val_loss: 0.7566 - val_accuracy: 0.7028\n",
            "Epoch 3/25\n",
            "69/69 [==============================] - 32s 463ms/step - loss: 0.9355 - accuracy: 0.6568 - val_loss: 0.6493 - val_accuracy: 0.7510\n",
            "Epoch 4/25\n",
            "69/69 [==============================] - 32s 463ms/step - loss: 0.7678 - accuracy: 0.6845 - val_loss: 0.5713 - val_accuracy: 0.7309\n",
            "Epoch 5/25\n",
            "69/69 [==============================] - 32s 461ms/step - loss: 0.6959 - accuracy: 0.7186 - val_loss: 0.4968 - val_accuracy: 0.7831\n",
            "Epoch 6/25\n",
            "69/69 [==============================] - 32s 463ms/step - loss: 0.5939 - accuracy: 0.7345 - val_loss: 0.4424 - val_accuracy: 0.8032\n",
            "Epoch 7/25\n",
            "69/69 [==============================] - 32s 462ms/step - loss: 0.5619 - accuracy: 0.7550 - val_loss: 0.4389 - val_accuracy: 0.8193\n",
            "Epoch 8/25\n",
            "69/69 [==============================] - 32s 461ms/step - loss: 0.5364 - accuracy: 0.7682 - val_loss: 0.3772 - val_accuracy: 0.8313\n",
            "Epoch 9/25\n",
            "69/69 [==============================] - 32s 458ms/step - loss: 0.5286 - accuracy: 0.7700 - val_loss: 0.3575 - val_accuracy: 0.8434\n",
            "Epoch 10/25\n",
            "69/69 [==============================] - 32s 459ms/step - loss: 0.4647 - accuracy: 0.7986 - val_loss: 0.3545 - val_accuracy: 0.8394\n",
            "Epoch 11/25\n",
            "69/69 [==============================] - 32s 458ms/step - loss: 0.4270 - accuracy: 0.8214 - val_loss: 0.3331 - val_accuracy: 0.8514\n",
            "Epoch 12/25\n",
            "69/69 [==============================] - 32s 458ms/step - loss: 0.4159 - accuracy: 0.8191 - val_loss: 0.3228 - val_accuracy: 0.8715\n",
            "Epoch 13/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3787 - accuracy: 0.8305 - val_loss: 0.3194 - val_accuracy: 0.8635\n",
            "Epoch 14/25\n",
            "69/69 [==============================] - 32s 458ms/step - loss: 0.3844 - accuracy: 0.8291 - val_loss: 0.3087 - val_accuracy: 0.8715\n",
            "Epoch 15/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3534 - accuracy: 0.8432 - val_loss: 0.3099 - val_accuracy: 0.8835\n",
            "Epoch 16/25\n",
            "69/69 [==============================] - 32s 461ms/step - loss: 0.3423 - accuracy: 0.8595 - val_loss: 0.3194 - val_accuracy: 0.8755\n",
            "Epoch 17/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3641 - accuracy: 0.8414 - val_loss: 0.3165 - val_accuracy: 0.8876\n",
            "Epoch 18/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3444 - accuracy: 0.8486 - val_loss: 0.2996 - val_accuracy: 0.8715\n",
            "Epoch 19/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3437 - accuracy: 0.8418 - val_loss: 0.3033 - val_accuracy: 0.8635\n",
            "Epoch 20/25\n",
            "69/69 [==============================] - 31s 455ms/step - loss: 0.3481 - accuracy: 0.8505 - val_loss: 0.3130 - val_accuracy: 0.8635\n",
            "Epoch 21/25\n",
            "69/69 [==============================] - 32s 457ms/step - loss: 0.3493 - accuracy: 0.8514 - val_loss: 0.3405 - val_accuracy: 0.8594\n",
            "Epoch 22/25\n",
            "69/69 [==============================] - 31s 456ms/step - loss: 0.3367 - accuracy: 0.8445 - val_loss: 0.2965 - val_accuracy: 0.8795\n",
            "Epoch 23/25\n",
            "69/69 [==============================] - 32s 458ms/step - loss: 0.3383 - accuracy: 0.8577 - val_loss: 0.2761 - val_accuracy: 0.8876\n",
            "Epoch 24/25\n",
            "69/69 [==============================] - 31s 455ms/step - loss: 0.3480 - accuracy: 0.8555 - val_loss: 0.3296 - val_accuracy: 0.8675\n",
            "Epoch 25/25\n",
            "69/69 [==============================] - 32s 459ms/step - loss: 0.3253 - accuracy: 0.8541 - val_loss: 0.2657 - val_accuracy: 0.8755\n",
            "[INFO] EVALUATING THE NETWORK...\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   group of babies       0.88      0.84      0.86       312\n",
            "   group of adults       0.97      0.96      0.96       237\n",
            "group of teenagers       0.83      0.87      0.85       278\n",
            "\n",
            "          accuracy                           0.89       827\n",
            "         macro avg       0.89      0.89      0.89       827\n",
            "      weighted avg       0.89      0.89      0.89       827\n",
            "\n",
            "[INFO] SERIALIZING NETWROK TO output/group classification model .... \n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Group_Classification/model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZcF3b8xGt4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3748f1a-4eaa-4b9e-ed1f-f50eb773cbd3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          51380736    Flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            1539        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 74,969,987\n",
            "Trainable params: 51,382,275\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoV1swUqGxVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Group_Classification/output/ResNet50model2.h5\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHE2OdDWG893",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"/content/drive/My Drive/Group_Classification/output/ResNet50model2.h5\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4LtxZf-jGuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHeKVFRSMbh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddcb60e0-0665-418e-e1a2-08d9e919215c"
      },
      "source": [
        "test  = pd.read_csv(\"/content/drive/My Drive/Group_Classification/output/Test.csv\")\n",
        "\n",
        "# print(test.shape)\n",
        "test_img = []\n",
        "# image = cv2.imread(\"/home/lohith/Documents/projects/Group_Classification/Test Data/Img3968.jpg\")\n",
        "\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    imagePath = \"/content/drive/My Drive/Group_Classification/Test Data/\" + test[\"Filename\"][i] \n",
        "    # print(imagePath)\n",
        "\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "\n",
        "    test_img.append(image)\n",
        "\n",
        "test = np.array(test_img)\n",
        "# print(test_img[0])   \n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 314/314 [00:02<00:00, 129.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hogiH7NIkuoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32c52cd7-4cfe-452a-c72a-a2cc207b68fd"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(314, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xstw96DbjE_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(test) \n",
        "final_pred =  lb.inverse_transform(prediction)\n",
        "test  = pd.read_csv(\"/content/drive/My Drive/Group_Classification/output/Test.csv\")\n",
        "test [\"Category\"] = final_pred\n",
        "test.Category = test.Category.map({\"group of adults\": \"Adults\", \"group of babaies\": \"Toddler\", \"group of teenagers\":\"Teenagers\"})\n",
        "test.to_csv(\"/content/drive/My Drive/Group_Classification/output/Submission_resnet50-2.csv\", index= False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifuwgg-aHbtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}